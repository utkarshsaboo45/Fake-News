{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6deffe-9c9a-4a8b-8fb8-f2c2608fc4eb",
   "metadata": {},
   "source": [
    "# Fake News Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729962c-4ce7-47d5-9c43-44f06b367537",
   "metadata": {},
   "source": [
    "### Data Reading and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573692a-e238-4943-a9bc-d270a041a2f1",
   "metadata": {},
   "source": [
    "__Import Statements__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc873ea-5618-4d36-804d-88a062312ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('data_server')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from os import path\n",
    "import re\n",
    "import string\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "\n",
    "# nltk.download('words')\n",
    "# nltk.download(\"cmudict\")\n",
    "# nltk.download(\"vader_lexicon\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import cmudict, stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from similarity.jarowinkler import JaroWinkler\n",
    "#from similarity.cosine import Cosine\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "alt.data_transformers.enable('data_server')\n",
    "# alt.renderers.enable('mimetype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e95dd17-6ad4-42fc-9745-a424d5690282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/raw/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ffc8a-2011-4472-8056-23be44fbb12f",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb239a-5edc-4d2a-82fe-f65b79be2fd2",
   "metadata": {},
   "source": [
    "- Deal NaNs/Nulls and empty texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3ea891-060a-4e64-a7bb-4dff4fca7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):\n",
    "    punctuations = string.punctuation\n",
    "    punctuations += \"“”–\\n\"\n",
    "\n",
    "    for element in word:\n",
    "        if element in punctuations:\n",
    "            word = word.replace(element, \"\")\n",
    "    return word\n",
    "\n",
    "\n",
    "def clean_data(text):\n",
    "    text = str(text).lower()\n",
    "    text = str(text).strip()\n",
    "    text\n",
    "    text = re.sub(\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15843fd4-dd50-4f42-8973-5295cea0b6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efc74f5-2210-4e8f-af6e-8aff86610904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"title\"] = train_df[\"title\"].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5807218-3bc0-42f7-9b60-e1fa4157a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"text\"].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b1674-2854-4308-a9a5-f482a86c4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a0b970-b262-4c08-8628-e556fc09cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbfcdd-d0fd-461e-8d2e-5f6b8af47e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060555c8-4c1e-4653-ab65-21ebdb7a5d6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625a8d8-da4f-472d-937b-f692a6cc6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102b5cd-6f44-4507-b535-a20ecf1bdfa3",
   "metadata": {},
   "source": [
    "__There is no class imbalance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1586a6a8-da5d-43c6-9f40-8b9809807f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake = \" \".join(train_df[train_df[\"label\"] == 1][\"text\"])\n",
    "real = \" \".join(train_df[train_df[\"label\"] == 0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c111cb1a-2fa2-4fc9-b607-7e5d3dd19590",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676e7b53-9244-4845-a41c-30670f555d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wordcloud_fake = WordCloud(\n",
    "#     stopwords=stop_words,\n",
    "#     max_font_size=40,\n",
    "#     width=400,\n",
    "#     height=200\n",
    "# ).generate(fake).to_image()\n",
    "\n",
    "# plt.imshow(wordcloud_fake)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932b756-4f6b-49d1-8409-04602c9feb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud_real = WordCloud(\n",
    "#     stopwords=stop_words,\n",
    "#     max_font_size=40,\n",
    "#     width=400,\n",
    "#     height=200\n",
    "# ).generate(real).to_image()\n",
    "\n",
    "# plt.imshow(wordcloud_real)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd3a61-9f3b-4122-93f9-be5db63c3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_counter = Counter(word for word in real.split(\" \") if word not in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb880641-c44b-4376-abb1-6a9f27443b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_counter = Counter(word for word in fake.split(\" \") if word not in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb84d4-a5e7-4311-8796-b1bc41fc54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d7d72-2aa8-4bc1-9f3d-d2e34945440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_real = pd.DataFrame.from_dict(\n",
    "#     real_counter,\n",
    "#     orient=\"index\",\n",
    "#     columns=[\"count\"]\n",
    "# ).reset_index().sort_values(\"count\", ascending=False).head(20)\n",
    "\n",
    "# df_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80374e91-7e97-4bff-825e-548ec5c9e8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_fake = pd.DataFrame.from_dict(\n",
    "#     fake_counter,\n",
    "#     orient=\"index\",\n",
    "#     columns=[\"count\"]\n",
    "# ).reset_index().sort_values(\"count\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65468305-3811-4ce8-8448-a7f2bd54c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(df_real, title=\"Frequency of top 10 words in Real News\").mark_bar().encode(\n",
    "#     x=\"index\",\n",
    "#     y=\"counts\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40af059-15cd-4ff4-81cf-c4fa540f0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(df_fake, title=\"Frequency of top 10 words in Fake News\").mark_bar().encode(\n",
    "#     alt.X(\"index\", sort=\"-y\"),\n",
    "#     alt.Y(\"count\")\n",
    "# )\n",
    "\n",
    "# plot = sns.countplot(x=\"index\", data = df_fake)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e4920-a375-4fc0-937f-571e9e52fa23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62673d40-7482-4569-93c4-37e77a17d212",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21864ca-d191-4c20-b8f9-30500a35be98",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Author Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f575df-4fcb-4539-8833-732ac1f8732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature \"author_is_null\"\n",
    "\n",
    "# def author_is_null(x):\n",
    "#     if x[\"author\"] != x[\"author\"]:\n",
    "#         return 0\n",
    "#     return 1\n",
    "\n",
    "# train_df[\"author_is_null\"] = train_df.apply(lambda x: author_is_null(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ddc58-1d4a-4716-a8e3-05ccee5670d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4adb788-5161-4ef8-9dc4-96fe72c0fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Author = Null to Author = \"Unknown\"\n",
    "\n",
    "# unknown_authors_ids = train_df.query(\"author.isnull()\")[\"id\"]\n",
    "# train_df['updated_author_column_name'] = np.where(~train_df['id'].isin(unknown_authors_ids), train_df['author'], 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0fe34-705e-4b25-ae4b-1cbbf1d9edf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe8d1a-9152-4587-8d89-cf5fc47947a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others category if value_counts of an author is less than 5\n",
    "\n",
    "# less_frequent = train_df['author'].value_counts()[train_df['author'].value_counts() <= 5].index.tolist()\n",
    "# train_df['author'] = np.where(train_df['author'].isin(less_frequent), 'Other', train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102e3fc-7242-4fd8-9ad9-bd4e8f0debfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140a1dc-f0c3-4b85-bd98-83d9c22fea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create if \"is_multiple_authors\"\n",
    "\n",
    "# def is_multiple_authors(data):\n",
    "\n",
    "#     data[\"is_multiple_authors\"] = [\n",
    "#         1 if \" and \" in str(author) else 0 for author in data[\"author\"]\n",
    "#     ]\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# train_df = is_multiple_authors(train_df)\n",
    "\n",
    "# train_df.query(\"is_multiple_authors == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c1ba8-e549-4e56-85b8-10e30814fe71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd2ba6-3e63-4f63-b1e1-cc52a3f996c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if author name contains a domain suffix\n",
    "\n",
    "# def author_contains_domain(data):\n",
    "\n",
    "#     data[\"author_contains_domain\"] = [\n",
    "#         1 if re.search(r\"\\.[a-zA-Z]{3}\", str(author)) else 0 for author in train_df[\"author\"]\n",
    "#     ]\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# train_df = author_contains_domain(train_df)\n",
    "\n",
    "# train_df.query(\"author_contains_domain == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731aee0-121c-44ec-b2b1-aedf8e93351b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91d952f0-399b-4f62-b625-0fd472b077b9",
   "metadata": {},
   "source": [
    "#### Title Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63ecf1-b40f-48e8-a97a-d1ed391c143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if title is null\n",
    "\n",
    "# def is_title_null(data):\n",
    "\n",
    "#     data[\"is_title_null\"] = [\n",
    "#         0 if title == title\n",
    "#         else 1 for title in train_df[\"title\"]\n",
    "#     ]\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# train_df = is_title_null(train_df)\n",
    "\n",
    "# train_df.query(\"is_title_null == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c143d-dda3-4f3b-8fb4-4b5cd625d219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85295f28-54d8-4ec9-852c-8d27fcbccfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if title ends with a famous journal name\n",
    "\n",
    "# def title_contains_famous_journal(data):\n",
    "\n",
    "#     data[\"title_contains_famous_journal\"] = [\n",
    "#         1 if\n",
    "#         str(title).endswith(\"The New York Times\") or\n",
    "#         str(title).endswith(\"Breitbart\")\n",
    "#         else 0 for title in train_df[\"title\"]\n",
    "#     ]\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# train_df = title_contains_famous_journal(train_df)\n",
    "\n",
    "# train_df.query(\"title_contains_famous_journal == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30be091-622d-4155-9e8a-dd606727d2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa58a3-237e-4dda-a643-1e4181c525d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def no_of_words(data):\n",
    "\n",
    "#     data[\"no_of_words\"] = [\n",
    "#         len(str(title).split(\" \")) for title in train_df[\"title\"]\n",
    "#     ]\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# train_df = no_of_words(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffae63b-4e57-4613-9706-ba19836f64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(train_df).mark_bar().encode(\n",
    "#     alt.X(\"no_of_words\", bin=alt.Bin(maxbins=50)),\n",
    "#     alt.Y(\"count()\"),\n",
    "#     color=\"label\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4e982-53a7-4a89-9946-8db5937c4f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14eef46-2d46-4871-8eaa-59fa789de226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def no_of_chars(data):\n",
    "\n",
    "#     data[\"no_of_chars\"] = [\n",
    "#         len(str(title)) for title in train_df[\"title\"]\n",
    "#     ]\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# train_df = no_of_chars(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba79f5-88c8-420d-a9c3-0dd4c38cbba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a7c36-8dd0-4991-af71-99ed33a1a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(train_df).mark_bar().encode(\n",
    "#     alt.X(\"no_of_chars\", bin=alt.Bin(maxbins=100)),\n",
    "#     alt.Y(\"count()\"),\n",
    "#     color=\"label\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06d160-0bce-4e32-8303-f220b6c5b733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b55bd27-276b-4d3f-a590-e3f37b4052bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_text_length(text):\n",
    "#     \"\"\"\n",
    "#     Returns the number of words in a text without punctuations. \n",
    "#     Counts clitics as separate words.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str\n",
    "#         A text from which we find the number of words\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     An int which represents the number of words in the text\n",
    "#     \"\"\"\n",
    "#     non_punc = []\n",
    "#     for word in word_tokenize(str(text)):\n",
    "#         if word not in string.punctuation:\n",
    "#             non_punc.append(word)\n",
    "#     return len(non_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280fbbe5-0134-4cf8-bfaa-f058a2ecf9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.assign(title_len=train_df[\"title\"].apply(get_text_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312c4aa-ffb2-486d-9d3f-43f94e8fe9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad8b6a-7961-4f68-a70b-54db1f215d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lexical_density(text):\n",
    "#     \"\"\"\n",
    "#     Returns the lexical density of a text. That is the ratio of open class words.\n",
    "#     in the text\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str\n",
    "#         A text from which we find the lexical density\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     A float which represents the lexical density\n",
    "#     \"\"\"\n",
    "#     open_class_prefix = {\"N\", \"V\", \"J\", \"R\"}\n",
    "#     open_class_total = 0\n",
    "#     word_count = 0\n",
    "#     if len(str(text)) == 0:\n",
    "#         return float(0)\n",
    "#     for word, pos in pos_tag(word_tokenize(str(text))):\n",
    "#         if word not in string.punctuation:\n",
    "#             word_count += 1\n",
    "#             if pos[0] in open_class_prefix:\n",
    "#                 open_class_total += 1\n",
    "#     return open_class_total/word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd42c14-8bef-467b-8250-4529282ab5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"title_lexical_density\"] = train_df[\"title\"].apply(get_lexical_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fee541-6649-49c2-9e9e-be497f94f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"text_lexical_density\"] = train_df[\"text\"].apply(get_lexical_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00ffc4-b816-488b-adee-ab218d351c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pos_count(text):\n",
    "#     \"\"\"\n",
    "#     Counts the number of nouns, verbs and adjectives in a text.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str\n",
    "#         A text for which we find the number of nouns, verbs\n",
    "#         and adjectives\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     A tuple of (noun_count: int, verb_count: int, adj_count: int)\n",
    "#     which represents the number of nouns, verbs adjectives in the text\n",
    "#     respectively\n",
    "#     \"\"\"\n",
    "#     noun_count = 0\n",
    "#     verb_count = 0\n",
    "#     adj_count = 0\n",
    "\n",
    "#     if len(str(text)) == 0:\n",
    "#         return 0, 0, 0\n",
    "\n",
    "#     for word, pos in pos_tag(word_tokenize(str(text))):\n",
    "#         if(pos[0] == 'N'):\n",
    "#             noun_count += 1\n",
    "#         if(pos[0] == 'V'):\n",
    "#             verb_count += 1\n",
    "#         if(pos == 'JJ'):\n",
    "#             adj_count += 1\n",
    "#     return noun_count\n",
    "#     return verb_count\n",
    "#     return adj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0696f3-ef17-4d0f-8c65-648c6d91b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"count_pos_title\"] = train_df[\"title\"].apply(get_pos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ce4b9-c202-44d2-9c3d-63c4ea64e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"count_noun_title\"], train_df[\"count_verb_title\"], train_df[\"count_adj_title\"] = train_df[\"count_pos_title\"].str[0],train_df[\"count_pos_title\"].str[1],train_df[\"count_pos_title\"].str[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d4900d-4e20-4957-9588-478d7c998405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_num_ovv_words(text):\n",
    "#     \"\"\"\n",
    "#     Gets the number of out-of-vocabulary words in a text.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     text : str\n",
    "#         A text for which we find the number of out-of-vocabulary\n",
    "#         words is to be found\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     The number of oov words in the text\n",
    "#     \"\"\"\n",
    "#     text_vocab = set(w for w in text.split() if w.isalpha())\n",
    "#     english_vocab = set(w for w in nltk.corpus.words.words())\n",
    "#     ovv_words = text_vocab - english_vocab\n",
    "\n",
    "#     return len(ovv_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe8bfa-5683-4e37-8660-9961ca72e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"title_ovw\"] = train_df[\"title\"].apply(get_num_ovv_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8710a2-6745-4b9e-9e7a-8581ef7f1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def contains_says(data):\n",
    "\n",
    "#     data[\"contains_says\"] = [\n",
    "#         1 if\n",
    "#         len(str(title).split(\" \")) < 6\n",
    "\n",
    "# #         re.search(\"[^a-zA-Z0-9 .,:'\\\"-\\\\$()]\", str(title))\n",
    "\n",
    "# #         re.search(\"[0-9]\", str(title))\n",
    "\n",
    "# #         \"Says\" in str(title) or \"says\" in str(title)\n",
    "\n",
    "#         else 0 for title in train_df[\"title\"]\n",
    "#     ]\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24fae8-2595-4d7b-ad47-14c1b11d7c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = contains_says(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea522e-2019-43a9-aedc-9620a9d10da3",
   "metadata": {},
   "source": [
    "#### Text Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416f162-6ae2-4f3b-9b6b-0ed76d2b4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if text is empty\n",
    "\n",
    "# def is_text_empty(data):\n",
    "\n",
    "#     data[\"is_text_empty\"] = [\n",
    "#         1 if text == \" \" or\n",
    "#         not text == text\n",
    "#         else 0 for text in train_df[\"text\"]\n",
    "#     ]\n",
    "\n",
    "#     return data\n",
    "# train_df.query(\"text == ' '\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65363a-61b9-42f0-ac16-2b2693450e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = is_text_empty(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590515b7-8e51-4dde-9dba-b44a36306abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df2.query(\"is_text_empty == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929a019-24c8-4cfe-8361-91959314846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"text_len\"] = train_df[\"text\"].apply(get_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a27fc-0135-456e-bbc3-7c585b49d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"text_ovw\"] = train_df[\"text\"].apply(get_num_ovv_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086216ea-8048-45f7-9493-fffb99a7b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"text_pos_count\"] = train_df[\"text\"].apply(get_pos_count)\n",
    "#train_df[\"count_noun_text\"], train_df[\"count_verb_text\"], train_df[\"count_adj_text\"] = train_df[\"text_pos_count\"].str[0],train_df[\"text_pos_count\"].str[1],train_df[\"text_pos_count\"].str[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300b763-17d3-40e1-b236-a96c198ec6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533eeaff-c9e2-4916-bb96-05c0d6e0bd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11de4f4-9071-4245-aac9-b7e84a2e0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1498ded5-647c-4206-a0cd-1fbb89d3e3f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cosine Similarity between Title and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e1a9b-e20c-4534-b025-4b5a6734ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine = Cosine(2)\n",
    "#train_df[\"p0\"] = train_df[\"title\"].apply(lambda s: cosine.get_profile(s))\n",
    "#train_df[\"p1\"] = train_df[\"text\"].apply(lambda s: cosine.get_profile(s))\n",
    "# train_df[\"cosine_sim\"] = [cosine.similarity_profiles(p0,p1) for p0, p1 in zip(train_df[\"p0\"],train_df[\"p1\"])]\n",
    "\n",
    "# train_df.drop([\"p0\", \"p1\"], axis=1)\n",
    "\n",
    "# jarowinkler = JaroWinkler()\n",
    "# df[\"jarowinkler_sim\"] = [jarowinkler.similarity(i,j) for i,j in zip(train_df[\"title\"],train_df[\"text\"])]\n",
    "\n",
    "#score = cosine_similarity(train_df['title'], train_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b07587-233d-48c9-8db2-23fb51e55639",
   "metadata": {},
   "source": [
    "### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdcaa3d-cf72-401a-b9d4-061f07beaa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1816a3c0-f36c-4717-a33e-62c4e2a07c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_small, val_df = train_test_split(train_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a5fbcc-5780-4cb6-9ce6-c3f1c07df16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df_small.drop(columns=[\"label\"]), train_df_small[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e546e26-5a79-4759-8f8a-99488a5439d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"text\"] = X_train[\"text\"].values.astype(\"U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47eadabf-601b-41a5-bab9-6e8f2fc8e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_features1 = [\"title\"] \n",
    "text_features2 = [\"text\"]\n",
    "pass_through = []\n",
    "drop = [\"id\", \"author\", \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ef11645-82e2-44d1-bacd-de9e8e6ef349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc1 = CountVectorizer(stop_words=\"english\", max_features=50)\n",
    "enc2 = CountVectorizer(stop_words=\"english\", max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3155ba4c-8c26-4430-90de-166728124cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe = make_pipeline(enc)\n",
    "preprocessor = make_column_transformer(\n",
    "    (enc2, text_features2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4372d9f-1707-4085-87e2-35ea767387b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef2799c0-ce86-46d5-a259-38d9c6bc6864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('countvectorizer',\n",
       "                                 CountVectorizer(max_features=100,\n",
       "                                                 stop_words='english'),\n",
       "                                 ['text'])])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5763876e-e584-4865-b898-6e74f480fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transfomed = preprocessor.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3a02c45-5c70-4965-ae03-12a30fef99d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0bb81-ac6d-4ec7-9728-0de219a97db0",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d20045-884b-429a-8a92-8f032c9923b4",
   "metadata": {},
   "source": [
    "__Split into Training and Validation data__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe43d5-b2a4-45bd-bd34-429bbdb12af2",
   "metadata": {},
   "source": [
    "#### Base models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c042eb-d700-4b2b-bf52-10374e952650",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression())\n",
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier())\n",
    "pipe_nb = make_pipeline(preprocessor, GaussianNB())\n",
    "pipe_svc = make_pipeline(preprocessor, SVC())\n",
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier())\n",
    "pipe_catboost = make_pipeline(preprocessor, CatBoostClassifier(verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a022c04-a208-4f51-8740-727183df048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    \"Logistic Regression\": pipe_lr\n",
    "#     \"Decision Tree\": pipe_dt,\n",
    "#     \"NB\": pipe_nb,\n",
    "#     \"SVC\": pipe_svc,\n",
    "#     \"Random Forest\": pipe_rf,\n",
    "#     \"Cat boost\": pipe_catboost\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148cd3b-cee7-4286-ad18-b3918dbac42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63a9d6-17c7-4664-90a4-00c036bf7ff1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f7fda-3dba-41c2-beb3-f41c24d981d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, value in models.items():\n",
    "    results[name] = mean_std_cross_val_scores(value, X_train_small, y_train_small, cv=10, return_train_score=True)\n",
    "    \n",
    "pd.DataFrame(results)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56b7d8-1379-47ec-ae20-669650dea5f7",
   "metadata": {},
   "source": [
    "#### HyperParam Tune best performing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d8513-fb39-4435-972e-3cebda3a10b4",
   "metadata": {},
   "source": [
    "### Prediction and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b931e18-6491-449b-a4f9-ce0bca144aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fake_news]",
   "language": "python",
   "name": "conda-env-fake_news-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
