{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6deffe-9c9a-4a8b-8fb8-f2c2608fc4eb",
   "metadata": {},
   "source": [
    "# Fake News Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729962c-4ce7-47d5-9c43-44f06b367537",
   "metadata": {},
   "source": [
    "### Data Reading and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573692a-e238-4943-a9bc-d270a041a2f1",
   "metadata": {},
   "source": [
    "__Import Statements__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc873ea-5618-4d36-804d-88a062312ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('data_server')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from os import path\n",
    "import re\n",
    "import string\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "\n",
    "# nltk.download('words')\n",
    "# nltk.download(\"cmudict\")\n",
    "# nltk.download(\"vader_lexicon\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import cmudict, stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer,\n",
    "    TfidfTransformer,\n",
    "    TfidfVectorizer\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from similarity.jarowinkler import JaroWinkler\n",
    "#from similarity.cosine import Cosine\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    FunctionTransformer\n",
    ")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "alt.data_transformers.enable('data_server')\n",
    "# alt.renderers.enable('mimetype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e95dd17-6ad4-42fc-9745-a424d5690282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read raw data\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists( \"../data/processed/train.csv\"):\n",
    "    train_df = pd.read_csv(\"../data/processed/train.csv\")\n",
    "    print(\"Read processed data\")\n",
    "else:\n",
    "    train_df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "    print(\"Read raw data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ffc8a-2011-4472-8056-23be44fbb12f",
   "metadata": {},
   "source": [
    "### Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bb239a-5edc-4d2a-82fe-f65b79be2fd2",
   "metadata": {},
   "source": [
    "- Deal NaNs/Nulls and empty texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3ea891-060a-4e64-a7bb-4dff4fca7055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):\n",
    "    punctuations = string.punctuation\n",
    "    punctuations += \"“”–\\n\"\n",
    "\n",
    "    for element in word:\n",
    "        if element in punctuations:\n",
    "            word = word.replace(element, \"\")\n",
    "    return word\n",
    "\n",
    "\n",
    "def clean_data(text):\n",
    "    text = str(text).lower()\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15843fd4-dd50-4f42-8973-5295cea0b6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efc74f5-2210-4e8f-af6e-8aff86610904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"title\"] = train_df[\"title\"].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5807218-3bc0-42f7-9b60-e1fa4157a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"text\"].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045b1674-2854-4308-a9a5-f482a86c4525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20800 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20800 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a0b970-b262-4c08-8628-e556fc09cada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title        0\n",
       "author    1957\n",
       "text         0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7cbfcdd-d0fd-461e-8d2e-5f6b8af47e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20800.000000</td>\n",
       "      <td>20800</td>\n",
       "      <td>18843</td>\n",
       "      <td>20800</td>\n",
       "      <td>20800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19708</td>\n",
       "      <td>4201</td>\n",
       "      <td>20380</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>Pam Key</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>558</td>\n",
       "      <td>243</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6004.587135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5199.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10399.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15599.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20799.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  title   author   text         label\n",
       "count   20800.000000  20800    18843  20800  20800.000000\n",
       "unique           NaN  19708     4201  20380           NaN\n",
       "top              NaN    nan  Pam Key                  NaN\n",
       "freq             NaN    558      243     77           NaN\n",
       "mean    10399.500000    NaN      NaN    NaN      0.500625\n",
       "std      6004.587135    NaN      NaN    NaN      0.500012\n",
       "min         0.000000    NaN      NaN    NaN      0.000000\n",
       "25%      5199.750000    NaN      NaN    NaN      0.000000\n",
       "50%     10399.500000    NaN      NaN    NaN      1.000000\n",
       "75%     15599.250000    NaN      NaN    NaN      1.000000\n",
       "max     20799.000000    NaN      NaN    NaN      1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060555c8-4c1e-4653-ab65-21ebdb7a5d6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7625a8d8-da4f-472d-937b-f692a6cc6f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102b5cd-6f44-4507-b535-a20ecf1bdfa3",
   "metadata": {},
   "source": [
    "__There is no class imbalance__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1586a6a8-da5d-43c6-9f40-8b9809807f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fake = \" \".join(train_df[train_df[\"label\"] == 1][\"text\"])\n",
    "real = \" \".join(train_df[train_df[\"label\"] == 0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c111cb1a-2fa2-4fc9-b607-7e5d3dd19590",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "676e7b53-9244-4845-a41c-30670f555d00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wordcloud_fake = WordCloud(\n",
    "#     stopwords=stop_words,\n",
    "#     max_font_size=40,\n",
    "#     width=400,\n",
    "#     height=200\n",
    "# ).generate(fake).to_image()\n",
    "\n",
    "# plt.imshow(wordcloud_fake)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e932b756-4f6b-49d1-8409-04602c9feb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud_real = WordCloud(\n",
    "#     stopwords=stop_words,\n",
    "#     max_font_size=40,\n",
    "#     width=400,\n",
    "#     height=200\n",
    "# ).generate(real).to_image()\n",
    "\n",
    "# plt.imshow(wordcloud_real)\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dcd3a61-9f3b-4122-93f9-be5db63c3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_counter = Counter(word for word in real.split(\" \") if word not in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb880641-c44b-4376-abb1-6a9f27443b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_counter = Counter(word for word in fake.split(\" \") if word not in stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4cb84d4-a5e7-4311-8796-b1bc41fc54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e22d7d72-2aa8-4bc1-9f3d-d2e34945440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_real = pd.DataFrame.from_dict(\n",
    "#     real_counter,\n",
    "#     orient=\"index\",\n",
    "#     columns=[\"count\"]\n",
    "# ).reset_index().sort_values(\"count\", ascending=False).head(20)\n",
    "\n",
    "# df_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80374e91-7e97-4bff-825e-548ec5c9e8f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_fake = pd.DataFrame.from_dict(\n",
    "#     fake_counter,\n",
    "#     orient=\"index\",\n",
    "#     columns=[\"count\"]\n",
    "# ).reset_index().sort_values(\"count\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65468305-3811-4ce8-8448-a7f2bd54c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(df_real, title=\"Frequency of top 10 words in Real News\").mark_bar().encode(\n",
    "#     x=\"index\",\n",
    "#     y=\"counts\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d40af059-15cd-4ff4-81cf-c4fa540f0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(df_fake, title=\"Frequency of top 10 words in Fake News\").mark_bar().encode(\n",
    "#     alt.X(\"index\", sort=\"-y\"),\n",
    "#     alt.Y(\"count\")\n",
    "# )\n",
    "\n",
    "# plot = sns.countplot(x=\"index\", data = df_fake)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e4920-a375-4fc0-937f-571e9e52fa23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62673d40-7482-4569-93c4-37e77a17d212",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21864ca-d191-4c20-b8f9-30500a35be98",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Author Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84f575df-4fcb-4539-8833-732ac1f8732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature \"author_is_null\"\n",
    "\n",
    "def author_is_null(x):\n",
    "    if x[\"author\"] != x[\"author\"]:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "train_df[\"author_is_null\"] = train_df.apply(lambda x: author_is_null(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4adb788-5161-4ef8-9dc4-96fe72c0fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Author = Null to Author = \"Unknown\"\n",
    "\n",
    "unknown_authors_ids = train_df.query(\"author.isnull()\")[\"id\"]\n",
    "train_df['updated_author_column_name'] = np.where(~train_df['id'].isin(unknown_authors_ids), train_df['author'], 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49fe8d1a-9152-4587-8d89-cf5fc47947a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others category if value_counts of an author is less than 5\n",
    "\n",
    "less_frequent = train_df['author'].value_counts()[train_df['author'].value_counts() <= 5].index.tolist()\n",
    "train_df['author'] = np.where(train_df['author'].isin(less_frequent), 'Other', train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c140a1dc-f0c3-4b85-bd98-83d9c22fea14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    198\n",
       "1      7\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create if \"is_multiple_authors\"\n",
    "\n",
    "def is_multiple_authors(data):\n",
    "\n",
    "    data[\"is_multiple_authors\"] = [\n",
    "        1 if \" and \" in str(author) else 0 for author in data[\"author\"]\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_df = is_multiple_authors(train_df)\n",
    "\n",
    "train_df.query(\"is_multiple_authors == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69dd2ba6-3e63-4f63-b1e1-cc52a3f996c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    480\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if author name contains a domain suffix\n",
    "\n",
    "def author_contains_domain(data):\n",
    "\n",
    "    data[\"author_contains_domain\"] = [\n",
    "        1 if re.search(r\"\\.[a-zA-Z]{3}\", str(author)) else 0 for author in train_df[\"author\"]\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_df = author_contains_domain(train_df)\n",
    "\n",
    "train_df.query(\"author_contains_domain == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d952f0-399b-4f62-b625-0fd472b077b9",
   "metadata": {},
   "source": [
    "#### Title Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad63ecf1-b40f-48e8-a97a-d1ed391c143c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: label, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if title is null\n",
    "\n",
    "def is_title_null(data):\n",
    "\n",
    "    data[\"is_title_null\"] = [\n",
    "        0 if title == title\n",
    "        else 1 for title in train_df[\"title\"]\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_df = is_title_null(train_df)\n",
    "\n",
    "train_df.query(\"is_title_null == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85295f28-54d8-4ec9-852c-8d27fcbccfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: label, dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if title ends with a famous journal name\n",
    "\n",
    "def title_contains_famous_journal(data):\n",
    "\n",
    "    data[\"title_contains_famous_journal\"] = [\n",
    "        1 if\n",
    "        str(title).endswith(\"The New York Times\") or\n",
    "        str(title).endswith(\"Breitbart\")\n",
    "        else 0 for title in train_df[\"title\"]\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_df = title_contains_famous_journal(train_df)\n",
    "\n",
    "train_df.query(\"title_contains_famous_journal == 1\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44fa58a3-237e-4dda-a643-1e4181c525d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_of_words(data):\n",
    "\n",
    "    data[\"no_of_words\"] = [\n",
    "        len(str(title).split(\" \")) for title in train_df[\"title\"]\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_df = no_of_words(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fffae63b-4e57-4613-9706-ba19836f64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(train_df).mark_bar().encode(\n",
    "#     alt.X(\"no_of_words\", bin=alt.Bin(maxbins=50)),\n",
    "#     alt.Y(\"count()\"),\n",
    "#     color=\"label\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b14eef46-2d46-4871-8eaa-59fa789de226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_of_chars(data):\n",
    "\n",
    "    data[\"no_of_chars\"] = [\n",
    "        len(str(title)) for title in train_df[\"title\"]\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "train_df = no_of_chars(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e7a7c36-8dd0-4991-af71-99ed33a1a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(train_df).mark_bar().encode(\n",
    "#     alt.X(\"no_of_chars\", bin=alt.Bin(maxbins=100)),\n",
    "#     alt.Y(\"count()\"),\n",
    "#     color=\"label\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b55bd27-276b-4d3f-a590-e3f37b4052bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_length(text):\n",
    "    \"\"\"\n",
    "    Returns the number of words in a text without punctuations. \n",
    "    Counts clitics as separate words.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A text from which we find the number of words\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An int which represents the number of words in the text\n",
    "    \"\"\"\n",
    "    non_punc = []\n",
    "    for word in word_tokenize(str(text)):\n",
    "        if word not in string.punctuation:\n",
    "            non_punc.append(word)\n",
    "    return len(non_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "280fbbe5-0134-4cf8-bfaa-f058a2ecf9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(title_len=train_df[\"title\"].apply(get_text_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca00ffc4-b816-488b-adee-ab218d351c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_count(text):\n",
    "    \"\"\"\n",
    "    Counts the number of nouns, verbs and adjectives in a text.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        A text for which we find the number of nouns, verbs\n",
    "        and adjectives\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (noun_count: int, verb_count: int, adj_count: int)\n",
    "    which represents the number of nouns, verbs adjectives in the text\n",
    "    respectively\n",
    "    \"\"\"\n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adj_count = 0\n",
    "\n",
    "    if len(str(text)) == 0:\n",
    "        return 0, 0, 0\n",
    "\n",
    "    for word, pos in pos_tag(word_tokenize(str(text))):\n",
    "        if(pos[0] == 'N'):\n",
    "            noun_count += 1\n",
    "        if(pos[0] == 'V'):\n",
    "            verb_count += 1\n",
    "        if(pos == 'JJ'):\n",
    "            adj_count += 1\n",
    "    return noun_count, verb_count, adj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca0696f3-ef17-4d0f-8c65-648c6d91b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_title = train_df[\"title\"].apply(get_pos_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "190ce4b9-c202-44d2-9c3d-63c4ea64e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"count_noun_title\"], train_df[\"count_verb_title\"], train_df[\"count_adj_title\"] = (\n",
    "    pos_title.str[0],\n",
    "    pos_title.str[1],\n",
    "    pos_title.str[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea522e-2019-43a9-aedc-9620a9d10da3",
   "metadata": {},
   "source": [
    "#### Text Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4416f162-6ae2-4f3b-9b6b-0ed76d2b4aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: label, dtype: int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Check if text is empty\n",
    "\n",
    "def is_text_empty(data):\n",
    "\n",
    "    data[\"is_text_empty\"] = [\n",
    "        1 if text == \" \" or\n",
    "        not text == text\n",
    "        else 0 for text in train_df[\"text\"]\n",
    "    ]\n",
    "\n",
    "    return data\n",
    "train_df.query(\"text == ' '\")[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca65363a-61b9-42f0-ac16-2b2693450e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = is_text_empty(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c929a019-24c8-4cfe-8361-91959314846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text_len\"] = train_df[\"text\"].apply(get_text_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "086216ea-8048-45f7-9493-fffb99a7b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_text = train_df[\"text\"].apply(get_pos_count)\n",
    "\n",
    "train_df[\"count_noun_text\"], train_df[\"count_verb_text\"], train_df[\"count_adj_text\"] = (\n",
    "    pos_text.str[0],\n",
    "    pos_text.str[1],\n",
    "    pos_text.str[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9300b763-17d3-40e1-b236-a96c198ec6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 25 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   id                             20800 non-null  int64  \n",
      " 1   title                          20800 non-null  object \n",
      " 2   author                         18843 non-null  object \n",
      " 3   text                           20800 non-null  object \n",
      " 4   label                          20800 non-null  int64  \n",
      " 5   author_is_null                 20800 non-null  int64  \n",
      " 6   updated_author_column_name     20800 non-null  object \n",
      " 7   is_multiple_authors            20800 non-null  int64  \n",
      " 8   author_contains_domain         20800 non-null  int64  \n",
      " 9   is_title_null                  20800 non-null  int64  \n",
      " 10  title_contains_famous_journal  20800 non-null  int64  \n",
      " 11  no_of_words                    20800 non-null  int64  \n",
      " 12  no_of_chars                    20800 non-null  int64  \n",
      " 13  title_len                      20800 non-null  int64  \n",
      " 14  count_pos_title                20800 non-null  object \n",
      " 15  count_noun_title               20800 non-null  int64  \n",
      " 16  count_verb_title               20800 non-null  int64  \n",
      " 17  count_adj_title                20800 non-null  int64  \n",
      " 18  is_text_empty                  20800 non-null  int64  \n",
      " 19  text_len                       20800 non-null  int64  \n",
      " 20  text_pos_count                 20800 non-null  object \n",
      " 21  count_noun_text                20800 non-null  int64  \n",
      " 22  count_verb_text                20800 non-null  int64  \n",
      " 23  count_adj_text                 20800 non-null  int64  \n",
      " 24  title_text_sim                 20800 non-null  float64\n",
      "dtypes: float64(1), int64(18), object(6)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533eeaff-c9e2-4916-bb96-05c0d6e0bd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11de4f4-9071-4245-aac9-b7e84a2e0b93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1498ded5-647c-4206-a0cd-1fbb89d3e3f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cosine Similarity between Title and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d68e1a9b-e20c-4534-b025-4b5a6734ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2):\n",
    "    str1_set = set(str1.split())\n",
    "    str2_set = set(str2.split())\n",
    "    intersection = str1_set.intersection(str2_set)\n",
    "    return float(len(intersection)) / (len(str1_set) + len(str2_set) - len(intersection))\n",
    "\n",
    "\n",
    "def get_title_text_similarity(data):\n",
    "    data[\"title_text_sim\"] = data.apply(lambda x: get_jaccard_sim(str(x[\"title\"]), str(x[\"text\"])), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e449adb3-0c38-42d2-a4ae-24dbdab73a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_title_text_similarity(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5bae314d-8410-4875-836d-1fa9d6faad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt.Chart(df).mark_bar().encode(\n",
    "#     alt.X(\"title_text_sim\", bin=alt.Bin(maxbins=50)),\n",
    "#     alt.Y(\"count()\"),\n",
    "#     color=\"label\"\n",
    "# ).properties(\n",
    "#     height=400,\n",
    "#     width=600\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a69ae-902d-4cf9-b099-b5627519bab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a440a4a3-0ad1-4ebe-b5b7-f610d6ca1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"text\"].values.astype(\"U\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e097f37d-cee2-4bac-a489-2b01d586e6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'author', 'text', 'label', 'author_is_null',\n",
       "       'updated_author_column_name', 'is_multiple_authors',\n",
       "       'author_contains_domain', 'is_title_null',\n",
       "       'title_contains_famous_journal', 'no_of_words', 'no_of_chars',\n",
       "       'title_len', 'count_pos_title', 'count_noun_title', 'count_verb_title',\n",
       "       'count_adj_title', 'is_text_empty', 'text_len', 'text_pos_count',\n",
       "       'count_noun_text', 'count_verb_text', 'count_adj_text',\n",
       "       'title_text_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b07587-233d-48c9-8db2-23fb51e55639",
   "metadata": {},
   "source": [
    "### Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1816a3c0-f36c-4717-a33e-62c4e2a07c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_small, val_df = train_test_split(train_df, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "85a5fbcc-5780-4cb6-9ce6-c3f1c07df16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df_small.drop(columns=[\"label\"]), train_df_small[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47eadabf-601b-41a5-bab9-6e8f2fc8e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features1 = [\n",
    "    \"title\"\n",
    "]\n",
    "text_features2 = [\n",
    "    \"text\"\n",
    "]\n",
    "binary_features = [\n",
    "    \"author_is_null\",\n",
    "    \"is_multiple_authors\",\n",
    "    \"author_contains_domain\",\n",
    "    \"is_title_null\", \n",
    "    \"title_contains_famous_journal\",\n",
    "    \"is_text_empty\"\n",
    "]\n",
    "numeric_features = [\n",
    "    \"no_of_words\",\n",
    "    \"no_of_chars\",\n",
    "    \"title_len\",\n",
    "    \"count_noun_title\",\n",
    "    \"count_verb_title\",\n",
    "    \"count_adj_title\",\n",
    "    \"text_len\",\n",
    "    \"count_noun_text\",\n",
    "    \"count_verb_text\",\n",
    "    \"count_adj_text\",\n",
    "    \"title_text_sim\"\n",
    "]\n",
    "pass_through = []\n",
    "\n",
    "drop = [\n",
    "    \"id\",\n",
    "    \"author\",\n",
    "    \"updated_author_column_name\",\n",
    "    \"count_pos_title\",\n",
    "    \"text_pos_count\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8dceeb7-5e82-4e95-b8da-951cfdde8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    len(text_features1) +\n",
    "    len(text_features2) +\n",
    "    len(binary_features) +\n",
    "    len(numeric_features) +\n",
    "    len(pass_through) +\n",
    "    len(drop)\n",
    ") == len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9215415-1d71-4892-807b-324ed102a603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16640 entries, 10250 to 19966\n",
      "Data columns (total 24 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   id                             16640 non-null  int64  \n",
      " 1   title                          16640 non-null  object \n",
      " 2   author                         15077 non-null  object \n",
      " 3   text                           16640 non-null  object \n",
      " 4   author_is_null                 16640 non-null  int64  \n",
      " 5   updated_author_column_name     16640 non-null  object \n",
      " 6   is_multiple_authors            16640 non-null  int64  \n",
      " 7   author_contains_domain         16640 non-null  int64  \n",
      " 8   is_title_null                  16640 non-null  int64  \n",
      " 9   title_contains_famous_journal  16640 non-null  int64  \n",
      " 10  no_of_words                    16640 non-null  int64  \n",
      " 11  no_of_chars                    16640 non-null  int64  \n",
      " 12  title_len                      16640 non-null  int64  \n",
      " 13  count_pos_title                16640 non-null  object \n",
      " 14  count_noun_title               16640 non-null  int64  \n",
      " 15  count_verb_title               16640 non-null  int64  \n",
      " 16  count_adj_title                16640 non-null  int64  \n",
      " 17  is_text_empty                  16640 non-null  int64  \n",
      " 18  text_len                       16640 non-null  int64  \n",
      " 19  text_pos_count                 16640 non-null  object \n",
      " 20  count_noun_text                16640 non-null  int64  \n",
      " 21  count_verb_text                16640 non-null  int64  \n",
      " 22  count_adj_text                 16640 non-null  int64  \n",
      " 23  title_text_sim                 16640 non-null  float64\n",
      "dtypes: float64(1), int64(17), object(6)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ef11645-82e2-44d1-bacd-de9e8e6ef349",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_transformer = FunctionTransformer(\n",
    "    np.reshape, kw_args={\"newshape\": -1}\n",
    ")\n",
    "\n",
    "enc1 = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    function_transformer,\n",
    "    CountVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=1000)\n",
    ")\n",
    "\n",
    "enc2 = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    function_transformer,\n",
    "    CountVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=1000)\n",
    ")\n",
    "\n",
    "standard_scalar = make_pipeline(StandardScaler())\n",
    "\n",
    "onehotencoder = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\", sparse=False, drop=\"if_binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac230a6-a36a-4630-8032-86d6907e12ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3155ba4c-8c26-4430-90de-166728124cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (enc1, text_features1),\n",
    "    (enc2, text_features2),\n",
    "    (standard_scalar, numeric_features),\n",
    "    (onehotencoder, binary_features),\n",
    "    (\"drop\", drop)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4372d9f-1707-4085-87e2-35ea767387b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function reshape at 0x10f485ea0>,\n",
       "                                                                      kw_args={'newshape': -1})),\n",
       "                                                 ('countvectorizer',\n",
       "                                                  CountVectorizer(max_features=1000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  stop_words='english'))]),\n",
       "                                 ['title']),\n",
       "                                ('pipeline-2',\n",
       "                                 Pipe...\n",
       "                                  'count_adj_text', 'title_text_sim']),\n",
       "                                ('pipeline-4',\n",
       "                                 Pipeline(steps=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary',\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse=False))]),\n",
       "                                 ['author_is_null', 'is_multiple_authors',\n",
       "                                  'author_contains_domain', 'is_title_null',\n",
       "                                  'title_contains_famous_journal',\n",
       "                                  'is_text_empty']),\n",
       "                                ('drop', 'drop',\n",
       "                                 ['id', 'author', 'updated_author_column_name',\n",
       "                                  'count_pos_title', 'text_pos_count'])])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ef2799c0-ce86-46d5-a259-38d9c6bc6864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function reshape at 0x10f485ea0>,\n",
       "                                                                      kw_args={'newshape': -1})),\n",
       "                                                 ('countvectorizer',\n",
       "                                                  CountVectorizer(max_features=1000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2),\n",
       "                                                                  stop_words='english'))]),\n",
       "                                 ['title']),\n",
       "                                ('pipeline-2',\n",
       "                                 Pipe...\n",
       "                                  'count_adj_text', 'title_text_sim']),\n",
       "                                ('pipeline-4',\n",
       "                                 Pipeline(steps=[('onehotencoder',\n",
       "                                                  OneHotEncoder(drop='if_binary',\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse=False))]),\n",
       "                                 ['author_is_null', 'is_multiple_authors',\n",
       "                                  'author_contains_domain', 'is_title_null',\n",
       "                                  'title_contains_famous_journal',\n",
       "                                  'is_text_empty']),\n",
       "                                ('drop', 'drop',\n",
       "                                 ['id', 'author', 'updated_author_column_name',\n",
       "                                  'count_pos_title', 'text_pos_count'])])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bee18410-2a08-4ef4-a9b3-b85a987ea7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = (\n",
    "    preprocessor.named_transformers_[\"pipeline-1\"].named_steps[\"countvectorizer\"].get_feature_names_out().tolist() + \n",
    "    preprocessor.named_transformers_[\"pipeline-2\"].named_steps[\"countvectorizer\"].get_feature_names_out().tolist() +\n",
    "    numeric_features +\n",
    "    binary_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5763876e-e584-4865-b898-6e74f480fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = preprocessor.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3a02c45-5c70-4965-ae03-12a30fef99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_transformed.toarray(), columns=new_cols).to_csv(\"apple.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6bdd7595-4c46-4101-8c80-701a6f310d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>...</th>\n",
       "      <th>count_noun_text</th>\n",
       "      <th>count_verb_text</th>\n",
       "      <th>count_adj_text</th>\n",
       "      <th>title_text_sim</th>\n",
       "      <th>author_is_null</th>\n",
       "      <th>is_multiple_authors</th>\n",
       "      <th>author_contains_domain</th>\n",
       "      <th>is_title_null</th>\n",
       "      <th>title_contains_famous_journal</th>\n",
       "      <th>is_text_empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.676403</td>\n",
       "      <td>-0.698509</td>\n",
       "      <td>-0.716584</td>\n",
       "      <td>1.511901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.619180</td>\n",
       "      <td>-0.585214</td>\n",
       "      <td>-0.669852</td>\n",
       "      <td>0.532795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.349979</td>\n",
       "      <td>0.822030</td>\n",
       "      <td>1.806930</td>\n",
       "      <td>-0.540106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.726895</td>\n",
       "      <td>-0.793916</td>\n",
       "      <td>-0.786681</td>\n",
       "      <td>0.749539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460974</td>\n",
       "      <td>-0.543474</td>\n",
       "      <td>-0.447876</td>\n",
       "      <td>0.429633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16635</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316232</td>\n",
       "      <td>-0.346698</td>\n",
       "      <td>-0.377779</td>\n",
       "      <td>0.107757</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16636</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050312</td>\n",
       "      <td>-0.096256</td>\n",
       "      <td>0.019441</td>\n",
       "      <td>-0.065191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828236</td>\n",
       "      <td>1.424283</td>\n",
       "      <td>1.117637</td>\n",
       "      <td>-0.530481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168484</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>0.194685</td>\n",
       "      <td>-0.347420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.501367</td>\n",
       "      <td>-0.555400</td>\n",
       "      <td>-0.494608</td>\n",
       "      <td>-0.008039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16640 rows × 2017 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        10  100   11   12   15   20  2016  2017   30   50  ...  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "...    ...  ...  ...  ...  ...  ...   ...   ...  ...  ...  ...   \n",
       "16635  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "16636  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "16637  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "16638  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "16639  0.0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   \n",
       "\n",
       "       count_noun_text  count_verb_text  count_adj_text  title_text_sim  \\\n",
       "0            -0.676403        -0.698509       -0.716584        1.511901   \n",
       "1            -0.619180        -0.585214       -0.669852        0.532795   \n",
       "2             1.349979         0.822030        1.806930       -0.540106   \n",
       "3            -0.726895        -0.793916       -0.786681        0.749539   \n",
       "4            -0.460974        -0.543474       -0.447876        0.429633   \n",
       "...                ...              ...             ...             ...   \n",
       "16635        -0.316232        -0.346698       -0.377779        0.107757   \n",
       "16636        -0.050312        -0.096256        0.019441       -0.065191   \n",
       "16637         0.828236         1.424283        1.117637       -0.530481   \n",
       "16638         0.168484        -0.000850        0.194685       -0.347420   \n",
       "16639        -0.501367        -0.555400       -0.494608       -0.008039   \n",
       "\n",
       "       author_is_null  is_multiple_authors  author_contains_domain  \\\n",
       "0                 1.0                  0.0                     0.0   \n",
       "1                 1.0                  0.0                     0.0   \n",
       "2                 1.0                  0.0                     0.0   \n",
       "3                 1.0                  0.0                     0.0   \n",
       "4                 1.0                  0.0                     0.0   \n",
       "...               ...                  ...                     ...   \n",
       "16635             1.0                  0.0                     0.0   \n",
       "16636             0.0                  0.0                     0.0   \n",
       "16637             1.0                  0.0                     0.0   \n",
       "16638             1.0                  0.0                     0.0   \n",
       "16639             1.0                  0.0                     0.0   \n",
       "\n",
       "       is_title_null  title_contains_famous_journal  is_text_empty  \n",
       "0                1.0                            1.0            1.0  \n",
       "1                1.0                            1.0            1.0  \n",
       "2                1.0                            1.0            1.0  \n",
       "3                1.0                            1.0            1.0  \n",
       "4                1.0                            1.0            1.0  \n",
       "...              ...                            ...            ...  \n",
       "16635            1.0                            1.0            1.0  \n",
       "16636            1.0                            1.0            1.0  \n",
       "16637            1.0                            1.0            1.0  \n",
       "16638            1.0                            1.0            1.0  \n",
       "16639            1.0                            1.0            1.0  \n",
       "\n",
       "[16640 rows x 2017 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_transfomed.toarray(), columns=new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d0bb81-ac6d-4ec7-9728-0de219a97db0",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d20045-884b-429a-8a92-8f032c9923b4",
   "metadata": {},
   "source": [
    "__Split into Training and Validation data__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fe43d5-b2a4-45bd-bd34-429bbdb12af2",
   "metadata": {},
   "source": [
    "#### Base models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c042eb-d700-4b2b-bf52-10374e952650",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(preprocessor, LogisticRegression(max_iter=100000))\n",
    "#pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier())\n",
    "pipe_nb = make_pipeline(\n",
    "    preprocessor,\n",
    "    FunctionTransformer(lambda x: x.todense(), accept_sparse=True),\n",
    "    GaussianNB())\n",
    "#pipe_svc = make_pipeline(preprocessor, SVC())\n",
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier())\n",
    "pipe_catboost = make_pipeline(preprocessor, CatBoostClassifier(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a022c04-a208-4f51-8740-727183df048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": pipe_lr,\n",
    "    #\"Decision Tree\": pipe_dt,\n",
    "    \"NB\": pipe_nb,\n",
    "    #\"SVC\": pipe_svc,\n",
    "    \"Random Forest\": pipe_rf,\n",
    "    \"Cat boost\": pipe_catboost\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148cd3b-cee7-4286-ad18-b3918dbac42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f63a9d6-17c7-4664-90a4-00c036bf7ff1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f7fda-3dba-41c2-beb3-f41c24d981d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, value in models.items():\n",
    "    print(f\"Start {name}!\")\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        value, X_train, y_train, cv=10, return_train_score=True\n",
    "    )\n",
    "    print(f\"Done {name}!\")\n",
    "    display(pd.DataFrame(results))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466aafd-1fe9-4789-ab49-3111e452f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6611971b-2d89-49f3-9f5c-18c894fecbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr.named_steps[\"logisticregression\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf18209-008f-4ac7-bfef-2dfc10c30c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Importance\": pipe_lr.named_steps[\"logisticregression\"].coef_.flatten(),\n",
    "    \"abs_Importance\": np.abs(pipe_lr.named_steps[\"logisticregression\"].coef_.flatten())\n",
    "}\n",
    "\n",
    "pd.DataFrame(data=data, index=new_cols).sort_values(\n",
    "    by=\"abs_Importance\", ascending=False\n",
    ")[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56b7d8-1379-47ec-ae20-669650dea5f7",
   "metadata": {},
   "source": [
    "#### HyperParam Tune best performing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d8513-fb39-4435-972e-3cebda3a10b4",
   "metadata": {},
   "source": [
    "### Prediction and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b931e18-6491-449b-a4f9-ce0bca144aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fake_news]",
   "language": "python",
   "name": "conda-env-fake_news-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
